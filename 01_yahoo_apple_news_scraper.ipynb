{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKASH4671/Sentiment-Analysis-on-Financial-News-and-Its-Impact-on-Stock-Prices/blob/main/01_yahoo_apple_news_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "Aza1gInm5Z4S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBKEdLWY5VTO"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "Y65r-AKm5hMU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwp90Rt5VTR"
      },
      "outputs": [],
      "source": [
        "# Set up ChromeDriver path (for Jupyter Notebook)\n",
        "chrome_options = Options()\n",
        "# chrome_options.add_argument(\"--headless\")  # Optional: if don't want to open browser window\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMnwe2tG5VTR"
      },
      "outputs": [],
      "source": [
        "#  Define path to chromedriver.exe (**note** - same folder)\n",
        "service = Service(\"chromedriver.exe\")\n",
        "# Launch the Chrome driver with options\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNqCCF3s5VTR",
        "outputId": "52316baa-4a19-466a-871c-852ad6469701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple Inc. (AAPL) Latest Stock News & Headlines - Yahoo Finance\n"
          ]
        }
      ],
      "source": [
        "# Yahoo Finance AAPL News\n",
        "driver.get(\"https://finance.yahoo.com/quote/AAPL/news?p=AAPL\")\n",
        "time.sleep(3)\n",
        "print(driver.title)\n",
        "# driver.quit() # Always close the driver at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR76wiDi5VTS"
      },
      "outputs": [],
      "source": [
        "# Scroll and load more news\n",
        "scroll_pause_time = 3\n",
        "scroll_count = 150  # can increase for more headlines\n",
        "\n",
        "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "scroll_pause_time = 1.5\n",
        "retries = 0\n",
        "\n",
        "for i in range(100):  # Try to scroll 100 times max\n",
        "    try:\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(scroll_pause_time)\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "        if new_height == last_height:\n",
        "            retries += 1\n",
        "            if retries > 3:  # Stop after 3 tries if nothing new is loading\n",
        "                print(f\" No new content after {i} scrolls. Ending scroll.\")\n",
        "                break\n",
        "        else:\n",
        "            retries = 0\n",
        "            last_height = new_height\n",
        "\n",
        "    except TimeoutException:\n",
        "        print(\" Timeout occurred during scroll. Exiting.\")\n",
        "        break\n",
        "\n",
        "print(\" Done scrolling.\")\n",
        "\n",
        "# Scrape news headlines\n",
        "print(\" Searching for updated news containers...\")\n",
        "\n",
        "articles = driver.find_elements(By.XPATH, '//div[@class=\"content yf-zt3p0l\"]/a')\n",
        "print(f\" Found {len(articles)} headlines\")\n",
        "\n",
        "news_data = []\n",
        "\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# scraping block\n",
        "news_data = []\n",
        "\n",
        "for article in articles:\n",
        "    try:\n",
        "        headline = article.find_element(By.TAG_NAME, \"h3\").text.strip()\n",
        "        link = article.get_attribute(\"href\")\n",
        "\n",
        "        #  Now get the parent div and find date text\n",
        "        parent_div = article.find_element(By.XPATH, \"..\")  # go to div.content\n",
        "        date_element = parent_div.find_element(By.CLASS_NAME, \"publishing\")\n",
        "        date_text = date_element.text.strip()  # Example: 'Yahoo Finance • 2 hours ago'\n",
        "\n",
        "        #  Extract relative time from the date string\n",
        "        if \"•\" in date_text:\n",
        "            relative_time = date_text.split(\"•\")[-1].strip()\n",
        "        else:\n",
        "            relative_time = date_text.strip()\n",
        "\n",
        "        # Convert \"2 hours ago\", \"3 days ago\", \"Yesterday\" → datetime\n",
        "        now = datetime.now()\n",
        "        if \"yesterday\" in relative_time.lower():\n",
        "            pub_date = now - timedelta(days=1)\n",
        "        elif \"hour\" in relative_time:\n",
        "            num = int(relative_time.split()[0])\n",
        "            pub_date = now - timedelta(hours=num)\n",
        "        elif \"minute\" in relative_time:\n",
        "            num = int(relative_time.split()[0])\n",
        "            pub_date = now - timedelta(minutes=num)\n",
        "        elif \"day\" in relative_time:\n",
        "            num = int(relative_time.split()[0])\n",
        "            pub_date = now - timedelta(days=num)\n",
        "        else:\n",
        "            pub_date = \"\"  # fallback if unknown format\n",
        "\n",
        "        news_data.append({\n",
        "            \"date\": pub_date.strftime(\"%Y-%m-%d\") if pub_date else \"\",\n",
        "            \"headline\": headline,\n",
        "            \"url\": link,\n",
        "            \"ticker\": \"AAPL\",\n",
        "            \"source\": \"Yahoo Finance\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\" Skipping due to error:\", e)\n",
        "        continue\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "df = pd.DataFrame(news_data)\n",
        "df.to_csv(\"apple_news.csv\", index=False)\n",
        "print(f\" Scraped {len(df)} Apple news articles and saved to 'apple_news.csv'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}